#!/usr/bin/env python3

import sys

sys.path.append('/opt/py')

import collections
import copy
import datetime
import io
import itertools
import json
import os
import pathlib
import platform
import random
import re
import shlex
import shutil
import subprocess
import tempfile
import xml.etree.ElementTree
import zipfile

import PIL.Image # PyPI: Pillow
import elevate # PyPI: elevate
import github # PyPI: PyGithub
import more_itertools # PyPI: more-itertools
import requests # PyPI: requests

import gitdir.host.github # https://github.com/fenhl/gitdir
import lazyjson # https://github.com/fenhl/lazyjson
import mse_to_json # https://github.com/fenhl/mse-to-json

try:
    BASE_PATH = pathlib.PosixPath(os.environ.get('LORESEEKERDATA', '/usr/local/share/fenhl/lore-seeker'))
except NotImplementedError:
    BASE_PATH = pathlib.PurePosixPath(os.environ.get('LORESEEKERDATA', '/usr/local/share/fenhl/lore-seeker'))
CACHE = {'set_files': {}}
STAGE = gitdir.host.github.GitHub().repo('fenhl/lore-seeker').stage_path
CACHING_FLAG = STAGE / 'frontend' / 'tmp' / 'caching-dev.txt'
CUSTOM_SETS = STAGE / 'data' / 'sets'
NAME_CHANGES_REGEX = re.compile('name-changes-v(.+)\\.txt')
PRECONS_PATHS = {
    'crawl': STAGE / 'data' / 'crawl-precons.json',
    'custard': STAGE / 'data' / 'custard-precons.json',
    'ech': STAGE / 'data' / 'ech-precons.json'
}
SUBCOMMANDS = {}

PRINTING_SPECIFIC_FIELDS = {
    'artist',
    'availability',
    'borderColor',
    'duelDeck',
    'flavorText',
    'foreignData',
    'frameEffect',
    'frameEffects',
    'frameVersion',
    'hasFoil',
    'hasNonFoil',
    'identifiers',
    'isArena',
    'isDateStamped',
    'isFullArt',
    'isMtgo',
    'isOnlineOnly',
    'isOversized',
    'isPaper',
    'isPromo',
    'isReprint',
    'isStarter',
    'isStorySpotlight',
    'isTextless',
    'isTimeshifted',
    'legalities', # recalculated by Lore Seeker
    'mcmId',
    'mcmMetaId',
    'mtgArenaId',
    'mtgoFoilId',
    'mtgoId',
    'mtgstocksId',
    'multiverseId',
    'number',
    'originalName',
    'originalText',
    'originalType',
    'promoTypes',
    'purchaseUrls',
    'rarity',
    'rulings', # migrated differently
    'scryfallId',
    'scryfallIllustrationId',
    'scryfallOracleId',
    'setCode',
    'tcgplayerProductId',
    'tcgplayerPurchaseUrl',
    'uuid',
    'variations',
    'watermark'
}

SIMPLE_FIELDS = [
    'artist',
    'borderColor',
    'colorIdentity',
    'colorIndicator',
    'colors',
    'convertedManaCost', #TODO recalculate from card['manaCost']?
    'faceConvertedManaCost', #TODO recalculate from card['manaCost']?
    'frameVersion',
    'hasFoil',
    'hasNonFoil',
    'isArena',
    'isMtgo',
    'isOnlineOnly',
    'isPaper',
    'layout',
    'loyalty',
    'manaCost',
    'power',
    'rarity',
    'side',
    'stability',
    'subtypes',
    'supertypes',
    'text',
    'toughness',
    'type', #TODO recalculate from supertypes/types/subtypes?
    'types',
    'watermark'
]

def subcommand(f, name=None):
    if isinstance(f, str):
        return lambda f_inner: subcommand(f_inner, name=f)
    if name is None:
        name = f.__name__
    SUBCOMMANDS[name] = f
    return f

@subcommand
def bcb(version):
    """Creates a new version of the Big Custom Box."""
    global BASE_PATH

    elevate.elevate() # the Cockatrice installer requires admin privileges
    if 'LORESEEKERDATA' not in os.environ:
        if yesno('Upload to dev?'):
            BASE_PATH = pathlib.PurePosixPath('/usr/local/share/fenhl/lore-seeker/dev')
        else:
            BASE_PATH = pathlib.PurePosixPath('/usr/local/share/fenhl/lore-seeker')
    bcb_dir = STAGE / 'data' / 'bcb'
    if bcb_dir.exists():
        shutil.rmtree(bcb_dir)
    bcb_dir.mkdir()
    # bcb
    (bcb_dir / 'bcb').mkdir()
    shutil.copy2(STAGE / 'data' / 'install-instructions-noimg.txt', bcb_dir / 'bcb' / 'INSTALL INSTRUCTIONS.txt')
    (bcb_dir / 'bcb' / 'XMLs').mkdir()
    for set_path in CUSTOM_SETS.iterdir():
        with set_path.open(encoding='utf-8') as set_f:
            set_json = json.load(set_f)
        if not set_json.get('custom', False):
            continue
        if 'setVersion' not in set_json['meta']:
            print(f'[ ** ] skipping set {set_json["code"]} as it has no version')
            continue
        shutil.copy2(pathlib.Path.home() / 'games' / 'magic' / 'set' / set_json['code'].lower() / f'v{set_json["meta"]["setVersion"]}' / 'trice-errata' / f'{set_json["code"]}.xml', bcb_dir / 'bcb' / 'XMLs' / f'{set_json["code"]}.xml')
    (bcb_dir / 'bcb' / 'decks').mkdir()
    (bcb_dir / 'bcb' / 'decks' / 'Custom Brawl').mkdir()
    with (STAGE / 'data' / 'crawl-precons.json').open(encoding='utf-8') as precons_f:
        precons = json.load(precons_f)
    for precon in precons:
        shutil.copy2(precon['path'], bcb_dir / 'bcb' / 'decks' / 'Custom Brawl' / f'{precon["name"]}.cod')
    (bcb_dir / 'bcb' / 'decks' / 'Custom Standard').mkdir()
    with (STAGE / 'data' / 'custard-precons.json').open(encoding='utf-8') as precons_f:
        precons = json.load(precons_f)
    for precon in precons:
        shutil.copy2(precon['path'], bcb_dir / 'bcb' / 'decks' / 'Custom Standard' / f'{precon["name"]}.cod')
    (bcb_dir / 'bcb' / 'decks' / 'ECH').mkdir()
    with (STAGE / 'data' / 'ech-precons.json').open(encoding='utf-8') as precons_f:
        precons = json.load(precons_f)
    for precon in precons:
        shutil.copy2(precon['path'], bcb_dir / 'bcb' / 'decks' / 'ECH' / f'{precon["name"]}.cod')
    shutil.copytree(STAGE / 'data' / 'promos', bcb_dir / 'bcb' / 'promos')
    with (bcb_dir / 'bcb' / 'version.txt').open('w', encoding='utf-8') as version_f:
        print(f'This is version {version} of the Big Custom Box (Loose Files, Images on Demand)', file=version_f)
    # bcb-img
    shutil.copytree(bcb_dir / 'bcb', bcb_dir / 'bcb-img')
    shutil.copy2(STAGE / 'data' / 'install-instructions-img.txt', bcb_dir / 'bcb-img' / 'INSTALL INSTRUCTIONS.txt')
    (bcb_dir / 'bcb-img' / 'images').mkdir()
    for set_path in CUSTOM_SETS.iterdir():
        with set_path.open(encoding='utf-8') as set_f:
            set_json = json.load(set_f)
        if not set_json.get('custom', False):
            continue
        if 'setVersion' not in set_json['meta']:
            print(f'[ ** ] skipping set {set_json["code"]} as it has no version')
            continue
        shutil.copy2(pathlib.Path.home() / 'games' / 'magic' / 'set' / set_json['code'].lower() / f'v{set_json["meta"]["setVersion"]}' / 'trice-errata' / f'{set_json["code"]}-files' / f'{set_json["code"]}.xml', bcb_dir / 'bcb-img' / 'XMLs' / f'{set_json["code"]}.xml')
        (bcb_dir / 'bcb-img' / 'images' / set_json['code']).mkdir()
        for img_path in (pathlib.Path.home() / 'games' / 'magic' / 'set' / set_json['code'].lower() / f'v{set_json["meta"]["setVersion"]}' / 'trice-errata' / f'{set_json["code"]}-files').iterdir():
            shutil.copy2(img_path, bcb_dir / 'bcb-img' / 'images' / set_json['code'])
    with (bcb_dir / 'bcb-img' / 'version.txt').open('w', encoding='utf-8') as version_f:
        print(f'This is version {version} of the Big Custom Box (Loose Files, Bundled Images)', file=version_f)
    # trice
    with requests.get(more_itertools.one(
        asset.browser_download_url
        for asset in github.Github().get_user('Cockatrice').get_repo('Cockatrice').get_latest_release().get_assets()
        if re.search('-win64\\.exe$', asset.name)
    ), stream=True) as response:
        response.raise_for_status()
        with (bcb_dir / 'install-trice.exe').open('wb') as trice_zip:
            shutil.copyfileobj(response.raw, trice_zip)
    subprocess.run([str(bcb_dir / 'install-trice.exe'), '/S', '/PORTABLE', f'/D={bcb_dir / "trice"}'], check=True)
    (bcb_dir / 'install-trice.exe').unlink()
    shutil.copytree(bcb_dir / 'bcb' / 'XMLs', bcb_dir / 'trice' / 'data' / 'customsets')
    shutil.copytree(bcb_dir / 'bcb' / 'decks', bcb_dir / 'trice' / 'data' / 'decks')
    (bcb_dir / 'trice' / 'data' / 'pics').mkdir()
    shutil.copytree(bcb_dir / 'bcb' / 'promos', bcb_dir / 'trice' / 'data' / 'pics' / 'CUSTOM')
    with (bcb_dir / 'trice' / 'version.txt').open('w', encoding='utf-8') as version_f:
        print(f'This is version {version} of the Big Custom Box (Full Install, Images on Demand)', file=version_f)
    # trice-img
    shutil.copytree(bcb_dir / 'trice', bcb_dir / 'trice-img')
    for xml_path in (bcb_dir / 'bcb-img' / 'XMLs').iterdir():
        shutil.copy2(xml_path, bcb_dir / 'trice-img' / 'data' / 'customsets')
    shutil.copytree(bcb_dir / 'bcb-img' / 'images', bcb_dir / 'trice-img' / 'data' / 'pics' / 'downloadedPics')
    with (bcb_dir / 'trice-img' / 'version.txt').open('w', encoding='utf-8') as version_f:
        print(f'This is version {version} of the Big Custom Box (Full Install, Bundled Images)', file=version_f)
    # upload
    for ds_store in bcb_dir.glob('**/.DS_Store'):
        ds_store.unlink()
    for box in {'bcb', 'bcb-img', 'trice', 'trice-img'}:
        with zipfile.ZipFile(bcb_dir / f'{box}.zip', 'w', zipfile.ZIP_DEFLATED) as z:
            for name, dirs, files in os.walk(bcb_dir / box):
                for filename in files:
                    file_path = pathlib.Path(name, filename)
                    z.write(file_path, file_path.relative_to(bcb_dir / box))
        shutil.rmtree(bcb_dir / box)
        subprocess.run(['scp', str(bcb_dir / f'{box}.zip'), f'{os.environ.get("LORE_SEEKER_HOSTNAME", "laire")}:{BASE_PATH / "repo" / "frontend" / "public" / "download" / (box + ".zip")}'], check=True)
        (bcb_dir / f'{box}.zip').unlink()
    run_remote([str(BASE_PATH / 'repo' / 'bin' / 'set-bcb-version'), version])
    bcb_dir.rmdir()

def build_name_map(ver_dir, old, new):
    if old['data'] == {}: # new set
        return {card['name']: (card['name'], card.get('originalName', card['name'])) for card in new['data']['cards']}
    if 'setVersion' in old.get('meta', {}):
        old_version = old['meta']['setVersion']
    elif 'version' in old:
        old_version = old['version']
    else:
        old_version = input(f'[ ?? ] {old["data"].get("name", ver_dir.parent.name)} old version: ')
    if 'setVersion' in new.get('meta', {}):
        new_version = new['meta']['setVersion']
    elif 'version' in new:
        new_version = new['version']
    else:
        new_version = input(f'[ ?? ] {new["data"]["name"]} new version: ')
    if 'cards' in old['data']:
        rename_path = ver_dir / f'name-changes-v{old_version}.txt'
        if rename_path.exists():
            if yesno(f'using existing card name mapping {rename_path}, edit now?'):
                subprocess.run(['nano', str(rename_path)], check=True)
        else:
            with rename_path.open('w', encoding='utf-8') as f:
                print('# name mapping between old version with errata and new version with errata', file=f)
                print(f'FROM {old_version}', file=f)
                for new_card in new['data']['cards']:
                    if not any(old_card['name'] == new_card['name'] for old_card in old['data']['cards']):
                        print(f'=> {new_card["name"]}', file=f)
                for old_card in old['data']['cards']:
                    if not any(old_card['name'] == new_card['name'] for new_card in new['data']['cards']):
                        print(f'{old_card["name"]} =>', file=f)
                for new_card in new['data']['cards']:
                    if any(old_card['name'] == new_card['name'] for old_card in old['data']['cards']):
                        print(f'{new_card["name"]} => {new_card["name"]}', file=f) #TODO remove these for brevity
            subprocess.run(['nano', str(rename_path)], check=True)
        name_map = parse_name_map(rename_path)[0]
        for new_card in new['data']['cards']:
            if new_card['name'] not in name_map:
                name_map[new_card['name']] = new_card['name'], new_card['name']
    elif old_version == new_version:
        name_map = {card['name']: (card['name'], card.get('originalName', card['name'])) for card in old['data']['cards']}
    else:
        name_map = {card['name']: (None, card.get('originalName', card['name'])) for card in new['data']['cards']}
    return name_map

def card_diff(set_code, card_name, old_card, new_card, errata_card=None):
    if errata_card is None:
        def card_diff_field(field_name):
            if field_name not in old_card and field_name in new_card:
                return 'added: {}: {}'.format(json.dumps(field_name), '    \n'.join(line for line in json.dumps(new_card[field_name]).split('\n')))
            elif field_name in old_card and field_name not in new_card:
                return 'removed: {}: {}'.format(json.dumps(field_name), '    \n'.join(line for line in json.dumps(old_card[field_name]).split('\n')))
            elif old_card[field_name] != new_card[field_name]:
                return 'old: {0}: {1}\n    new: {0}: {1}'.format(
                    json.dumps(field_name),
                    '    \n'.join(line for line in json.dumps(old_card[field_name]).split('\n')),
                    '    \n'.join(line for line in json.dumps(new_card[field_name]).split('\n'))
                )
            else:
                return None
    else:
        def card_diff_field(field_name):
            if field_name in new_card and field_name in errata_card and (field_name not in old_card or old_card[field_name] != new_card[field_name] == errata_card[field_name]):
                return '# old: {}\n    # new: {}\n    {}: {}'.format(
                    '    \n'.join(line for line in json.dumps(old_card[field_name]).split('\n')) if field_name in old_card else 'missing',
                    '    \n'.join(line for line in json.dumps(new_card[field_name]).split('\n')),
                    json.dumps(field_name),
                    '    \n'.join(line for line in json.dumps(errata_card[field_name]).split('\n'))
                )
            elif field_name in old_card and field_name not in new_card and field_name not in errata_card:
                return '# {} removed, was {}'.format(json.dumps(field_name), '    \n'.join(line for line in json.dumps(old_card[field_name]).split('\n')))
            else:
                return '{}: {}'.format(json.dumps(field_name), '    \n'.join(line for line in json.dumps(errata_card[field_name]).split('\n')))

    return f'# {card_name} ({set_code})\n{{\n    ' + ',\n    '.join(
        card_diff_field(field_name)
        for field_name in SIMPLE_FIELDS
        if field_name in old_card or field_name in (new_card if errata_card is None else errata_card)
        and card_diff_field(field_name) is not None
    ) + '\n}'

def choose(question, choices, *, allow_empty=False, shorten=True):
    answer = input(f'[ ?? ] {question} [{"/".join((choice[0] if shorten else choice) for choice in choices)}] ')
    while True:
        if allow_empty and not answer:
            return None
        for choice in choices:
            if answer.lower() in ({choice[0].lower(), choice.lower()} if shorten else {choice.lower()}):
                return choice
        answer = input('[ ?? ] unrecognized answer, type {}: '.format(join((f'“{choice}”' for choice in choices), word='or')))

def custom_sets():
    if 'custom_sets' not in CACHE:
        CACHE['custom_sets'] = {}
        for set_path in CUSTOM_SETS.iterdir():
            with set_path.open(encoding='utf-8') as f:
                set_file = json.load(f)
            if set_file.get('custom', False):
                CACHE['custom_sets'][set_file['code']] = set_file
    return CACHE['custom_sets']

@subcommand
def debug(*args):
    if '--cache' in args:
        if not CACHING_FLAG.exists():
            with CACHING_FLAG.open('w', encoding='utf-8'):
                pass # write empty file
    else:
        if CACHING_FLAG.exists():
            CACHING_FLAG.unlink()
    with (BASE_PATH / 'config.json').open(encoding='utf-8') as config_f:
        config = json.load(config_f)
    env = {
        'DISCORD_CLIENT_ID': config['clientID'],
        'DISCORD_CLIENT_SECRET': config['clientSecret'],
        **os.environ
    }
    was_running = subprocess.run(['systemctl', 'is-active', '--quiet', 'lore-seeker-dev']).returncode == 0
    if was_running:
        subprocess.run(['sudo', 'systemctl', 'stop', 'lore-seeker-dev'], check=True)
    try:
        exit_code = subprocess.run(['bundle', 'exec', 'rails', 'server', '-p', '18808'], env=env, cwd=STAGE / 'frontend').returncode
    except KeyboardInterrupt:
        exit_code = 0
    if was_running:
        subprocess.run(['sudo', 'systemctl', 'start', 'lore-seeker-dev'], check=True)
    return exit_code

@subcommand
def diff(set_code, old_version, new_version):
    set_dir = pathlib.Path.home() / 'games' / 'magic' / 'set' / set_code.lower()
    if not set_dir.exists():
        raise FileNotFoundError(f'No such set directory: {set_dir}')
    old_ver_dir = set_dir / f'v{old_version}'
    if (old_ver_dir / 'errata.mse-set').exists():
        with zipfile.ZipFile(old_ver_dir / 'errata.mse-set') as set_file:
            old_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=old_version)
    else:
        with zipfile.ZipFile(old_ver_dir / 'set.mse-set') as set_file:
            old_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=old_version)
    new_ver_dir = set_dir / f'v{new_version}'
    if (new_ver_dir / 'errata.mse-set').exists():
        with zipfile.ZipFile(new_ver_dir / 'errata.mse-set') as set_file:
            new_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=new_version)
    else:
        with zipfile.ZipFile(new_ver_dir / 'set.mse-set') as set_file:
            new_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=new_version)
    print(diff_set_jsons(new_ver_dir, old_set_json, new_set_json))

def diff_set_jsons(new_ver_dir, old, new):
    name_map = build_name_map(new_ver_dir, old, new)
    set_json['cards'] = []
    for old_card in old.get('cards', []):
        if not any(old_card['name'] == name_map[new_card['name']][0] for new_card in new['cards']):
            yield f'# {old_card["name"]}: card removed'
    for new_card in new['cards']:
        for old_card in old.get('cards', []):
            if old_card['name'] == name_map[new_card['name']][0]:
                break
        else:
            yield f'# {new_card["name"]}: card added'
            continue
        reprint_card, card_name, card = merge_card_fields(reprint_card, old_card, new_card, errata_card, None if reprint_card is None else reprint_set['code'], set_json['code'])
        card['name'] = card_name
        set_json['cards'].append(card)
    return set_json

def edit(original):
    with tempfile.NamedTemporaryFile('w', delete=False) as f:
        f.write(original)
        tmp = pathlib.Path(f.name)
    if platform.system() == 'Windows':
        subprocess.run([str(pathlib.Path.home() / 'AppData' / 'Local' / 'atom' / 'bin' / 'atom.cmd'), '--wait', str(tmp)], check=True)
    else:
        subprocess.run(['nano', str(tmp)], check=True)
    with tmp.open(encoding='utf-8') as f:
        edited = f.read()
    tmp.unlink()
    return edited

def edit_rulings(card_name, old_rulings):
    rulings_path = STAGE / 'tmp-rulings.json'
    if rulings_path.exists():
        with rulings_path.open() as f:
            tmp_rulings = json.load(f)
    else:
        tmp_rulings = {}
    edited_rulings = edit(f'# rulings for {card_name}\n' + '\n'.join(f'{ruling["date"]} {ruling["text"]}' for ruling in tmp_rulings.get(card_name, old_rulings)))
    tmp_rulings[card_name] = [
        {'date': line[:len('YYYY-mm-dd')], 'text': line[len('YYYY-mm-dd '):]}
        for line in edited_rulings.splitlines()
        if not line.strip().startswith('#')
    ]
    with rulings_path.open('w') as f:
        json.dump(tmp_rulings, f, indent=4, sort_keys=True)
        print(file=f)
    return tmp_rulings[card_name]

def find_card(card_name, set_info=None):
    if isinstance(set_info, dict):
        candidates = [
            (set_info['code'], card)
            for card in set_info['cards']
            if card['name'] == card_name
        ]
    else:
        candidates = [
            (set_file['code'], card)
            for set_file in custom_sets().values()
            for card in set_file['cards']
            if card['name'] == card_name
            and (set_info is None or set_file['code'] == set_info)
        ]
    if len(candidates) > 1:
        set_codes = sorted({set_code for set_code, card in candidates})
        if len(set_codes) > 1:
            set_code = choose(f'set code for {card_name}? (leave blank to randomize)', set_codes, allow_empty=True, shorten=False)
            if set_code is not None:
                candidates = [
                    (set_code, card)
                    for iter_set_code, card in candidates
                    if iter_set_code == set_code
                ]
    if len(candidates) > 1:
        set_codes = sorted({set_code for set_code, card in candidates})
        numbers = sorted({card['number'] for set_code, card in candidates})
        if len(set_codes) == 1 and len(numbers) > 1:
            number = choose(f'collector number for {card_name}? (leave blank to randomize)', numbers, allow_empty=True, shorten=False)
            if number is not None:
                candidates = [
                    (set_code, card)
                    for set_code, card in candidates
                    if card['number'] == number
                ]
    try:
        return random.choice(candidates)
    except IndexError as e:
        raise IndexError(f'Could not find card {card_name}') from e

def get_cached_set_file(set_path): #TODO replace with usage of custom_sets()
    set_path = set_path.resolve()
    if set_path not in CACHE['set_files']:
        with set_path.open(encoding='utf-8') as set_f:
            set_json = json.load(set_f)
            if 'data' not in set_json: # MTG JSON 4 or magic-search-engine's current weird mix of 4 and 5
                set_json = {'data': set_json, 'meta': set_json['meta']}
                del set_json['data']['meta']
            CACHE['set_files'][set_path] = set_json
    return CACHE['set_files'][set_path]

def img_dirs(set_info, version):
    set_name = set_info['name']
    set_dir = pathlib.Path.home() / 'games' / 'magic' / 'set' / set_info['code'].lower()
    card_count = collections.defaultdict(lambda: 0)
    # check if new-style Cockatrice export exists and use only that if it does
    errata_img_dir = set_dir / f'v{version}' / 'trice-errata'
    original_img_dir = set_dir / f'v{version}' / 'trice'
    if errata_img_dir.exists() and original_img_dir.exists():
        if os.environ.get('LSIMG_ERRATA', 'yes') == 'yes':
            errata = True
        elif os.environ.get('LSIMG_ERRATA', 'yes') == 'no':
            errata = False
        else:
            errata = yesno(f"use errata'd images for {set_info['code']}?")
        if errata:
            return [errata_img_dir]
        else:
            return [original_img_dir]
    elif not (errata_img_dir.exists() or original_img_dir.exists()):
        pass # new-style Cockatrice export doesn't exist, use old-style source dir
    else:
        return [more_itertools.one(dir for dir in [errata_img_dir, original_img_dir] if dir.exists())]
    # determine old-style source dir
    errata_img_dir = set_dir / f'v{version}' / 'img-errata'
    original_img_dir = set_dir / f'v{version}' / 'img'
    if errata_img_dir.exists() and original_img_dir.exists():
        if os.environ.get('LSIMG_ERRATA', 'yes') == 'yes':
            errata = True
        elif os.environ.get('LSIMG_ERRATA', 'yes') == 'no':
            errata = False
        else:
            errata = yesno(f"use errata'd images for {set_info['code']}?")
        if errata:
            return [errata_img_dir, original_img_dir]
        else:
            return [original_img_dir, errata_img_dir]
    elif not (errata_img_dir.exists() or original_img_dir.exists()):
        raise FileNotFoundError(f'no images directory found for {set_info["code"]} version {version}')
    else:
        return [more_itertools.one(dir for dir in [errata_img_dir, original_img_dir] if dir.exists())]

def img_filename(card_name, set_img_dirs, count=0, *, original_name=None):
    # generate all possible variants of the filename
    transformations = [
        lambda filename: ([
            filename,
            filename.split(':', 1)[1],
            filename.replace(':', '')
        ] if ':' in filename else [filename]),
        lambda filename: [
            filename,
            filename.replace("'", '').replace('‘', '').replace('’', ''),
            filename.replace("'", '’'),
            filename.replace("'", '_')
        ],
        lambda filename: [
            filename,
            filename.replace(',', ''),
            filename.replace(',', '_')
        ],
        lambda filename: ([f'{filename}.{count}', filename] if count > 0 else [filename]),
        lambda filename: [f'{filename}.full', filename],
        lambda filename: [f'{filename}.png', f'{filename}.jpg']
    ]
    if original_name is None:
        filenames = [card_name]
    else:
        filenames = [card_name, original_name]
    for transformation in transformations:
        filenames = list(more_itertools.flatten(map(transformation, filenames)))
    paths = [img_dir / filename for img_dir in set_img_dirs for filename in filenames]
    # check variants for existing files in order
    for path in paths:
        if path.exists():
            if path.suffix == '.jpg':
                new_path = path.parent / f'{path.stem}.png'
                subprocess.run(['convert', str(path), str(new_path)], check=True)
                path.unlink()
                path = new_path
            return path
    raise ValueError(f'Image file for {card_name} not found in {set_img_dirs}')

@subcommand('import')
def import_set(set_code, set_version, *options):
    is_commander = '--commander' in options
    if not is_commander:
        try:
            gefolge_conf = lazyjson.SFTPFile('mercredi.fenhl.net', 22, '/usr/local/share/fidera/games/magic.json', username='fenhl')
        except Exception as e:
            print(f'[ !! ] failed to access mercredi to check/edit gefolge.org blurb: {e.__class__.__name__}: {e}', file=sys.stderr)
        else:
            if set_code not in gefolge_conf['customSets']:
                gefolge_conf['customSets'][set_code] = {}
            if 'drafted' not in gefolge_conf['customSets'][set_code] and 'blurb' not in gefolge_conf['customSets'][set_code]:
                gefolge_conf['customSets'][set_code]['blurb'] = input(f'Beschreibung für gefolge.org: {set_code} ')
    set_dir = pathlib.Path.home() / 'games' / 'magic' / 'set' / set_code.lower()
    if not set_dir.exists():
        raise FileNotFoundError(f'No such set directory: {set_dir}')
    ver_dir = set_dir / f'v{set_version}'
    # read errata_set_json
    #TODO `mse.com --export magic-json errata.mse-set errata.json`
    if (ver_dir / 'errata.json').exists():
        with (ver_dir / 'errata.json').open() as set_file:
            errata_set_json = json.load(set_file)
        errata_set_json['meta']['setVersion'] = set_version
    elif (ver_dir / 'set.json').exists() and (ver_dir / 'errata.mse-set').exists():
        raise FileNotFoundError(f'found set.json and errata.mse-set but not errata.json')
    elif (ver_dir / 'set.json').exists():
        with (ver_dir / 'set.json').open() as set_file:
            errata_set_json = json.load(set_file)
        errata_set_json['meta']['setVersion'] = set_version
    elif (ver_dir / 'errata.mse-set').exists():
        with zipfile.ZipFile(ver_dir / 'errata.mse-set') as set_file:
            errata_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=set_version)
    else:
        with zipfile.ZipFile(ver_dir / 'set.mse-set') as set_file:
            errata_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=set_version)
    # read new_set_json
    #TODO `mse.com --export magic-json set.mse-set set.json`
    if (ver_dir / 'set.json').exists():
        with (ver_dir / 'set.json').open() as set_file:
            new_set_json = json.load(set_file)
        new_set_json['meta']['setVersion'] = set_version
    elif (ver_dir / 'errata.json').exists() and (ver_dir / 'set.mse-set').exists():
        raise FileNotFoundError(f'found errata.json and set.mse-set but not set.json')
    elif (ver_dir / 'errata.json').exists():
        with (ver_dir / 'errata.json').open() as set_file:
            new_set_json = json.load(set_file)
        new_set_json['meta']['setVersion'] = set_version
    elif (ver_dir / 'set.mse-set').exists():
        with zipfile.ZipFile(ver_dir / 'set.mse-set') as set_file:
            new_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=set_version)
    else:
        with zipfile.ZipFile(ver_dir / 'errata.mse-set') as set_file:
            new_set_json = mse_to_json.convert_mse_set(set_file, set_code=set_code, version=set_version)
    # read old_set_json
    set_json_path = CUSTOM_SETS / f'{set_code}.json'
    if set_json_path.exists():
        with set_json_path.open(encoding='utf-8') as set_file:
            old_set_json = json.load(set_file)
    else:
        old_set_json = {'data': {}, 'meta': {'date': f'{datetime.datetime.utcnow():%Y-%m-%d}', 'verison': '5.0.0'}}
    set_json = merge_set_jsons(set_json_path, ver_dir, old=old_set_json, new=new_set_json, errata=errata_set_json, is_commander=is_commander)
    with set_json_path.open('w', encoding='utf-8') as set_file:
        json.dump(set_json, set_file, indent=4, sort_keys=True)
        print(file=set_file)
    update_precons()

@subcommand('import-all')
def import_all():
    set_infos = {path.stem: lazyjson.File(path) for path in CUSTOM_SETS.iterdir() if lazyjson.File(path).get('custom', False)}
    for set_code, set_info in sorted(set_infos.items()):
        if 'setVersion' in set_info.get('meta', {}):
            version = set_info['meta']['setVersion'].value()
        elif 'version' in set_info:
            version = set_info['version'].value()
        else:
            print(f'[ ** ] skipping {set_info["name"]} (no version info found)')
            continue
        if set_code.startswith('M') and set_code[1:] in set_infos:
            import_set(set_code, version, '--commander')
        else:
            import_set(set_code, version)

def input_default(question, default, convert=lambda x: x):
    result = input(f'[ ?? ] {question} [{default}]: ').strip()
    if result == '':
        return default
    return convert(result)

def join(words, default=None, word='and'):
    words = list(words)
    if len(words) == 0:
        return default
    elif len(words) == 1:
        return words[0]
    elif len(words) == 2:
        return f'{words[0]} {word} {words[1]}'
    else:
        return ', '.join(words[:-1]) + f', {word} {words[-1]}'

def merge_card_fields(reprint_card, old_card, new_card, errata_card, reprint_set_code, set_code):
    card_name = errata_card['name']
    if reprint_card is not None and any(
        not reprint_eq(field_name, reprint_card.get(field_name), errata_card.get(field_name))
        for field_name in set(reprint_card).union(errata_card) - PRINTING_SPECIFIC_FIELDS
    ):
        print(f'[ ** ] {reprint_set_code}/{set_code} reprint changes for {card_name}')
        for field_name in sorted(set(reprint_card).union(errata_card) - PRINTING_SPECIFIC_FIELDS):
            if field_name not in reprint_card and field_name in errata_card:
                print(f'[ ** ] new {field_name}: {json.dumps(errata_card.get(field_name))}')
            elif field_name in reprint_card and field_name not in errata_card:
                print(f'[ ** ] {field_name} removed, was {json.dumps(reprint_card.get(field_name))}')
            elif not reprint_eq(field_name, reprint_card.get(field_name), errata_card.get(field_name)):
                print(f'[ ** ] {field_name}:')
                print(f'[{reprint_set_code}{":" if len(reprint_set_code) < 4 else ""}] {json.dumps(reprint_card.get(field_name))}')
                print(f'[{set_code}{":" if len(set_code) < 4 else ""}] {json.dumps(errata_card.get(field_name))}')
        if yesno('some fields differ in reprint, prefix card name with set code?'):
            card_name = f'{set_code}:{card_name}'
            reprint_card = None
    if reprint_card is None and old_card is None:
        # always review new cards
        json_card = json.dumps({
            field_name: field_value
            for field_name, field_value in errata_card.items()
            if field_name in SIMPLE_FIELDS
        }, indent=4, sort_keys=True)
        edited = edit(f'# {card_name} ({set_code}, new card)\n{json_card}')
        return reprint_card, card_name, json.loads('\n'.join(
            line
            for line in edited.splitlines()
            if not line.strip().startswith('#')
        ))
    elif old_card is not None and new_card is not None and any(
        ((field_name in old_card) != (field_name in new_card) and (field_name in new_card) == (field_name in errata_card))
        or old_card.get(field_name) != new_card.get(field_name) == errata_card.get(field_name)
        for field_name in SIMPLE_FIELDS
        if field_name not in {'isArena', 'isMtgo', 'isOnlineOnly', 'isPaper'} #TODO remove
    ):
        print(f'[ ** ] changes for {card_name}')
        for field_name in SIMPLE_FIELDS:
            if field_name in {'isArena', 'isMtgo', 'isOnlineOnly', 'isPaper'}: #TODO remove
                continue
            if field_name not in old_card and field_name in new_card and field_name in errata_card and new_card[field_name] == errata_card[field_name]:
                print(f'[ ** ] new {field_name}: {json.dumps(new_card.get(field_name))}')
            elif field_name in old_card and field_name not in new_card and field_name not in errata_card:
                print(f'[ ** ] {field_name} removed, was {json.dumps(old_card.get(field_name))}')
            elif old_card.get(field_name) != new_card.get(field_name) == errata_card.get(field_name):
                print(f'[ ** ] {field_name}:')
                print(f'[old:] {json.dumps(old_card.get(field_name))}')
                print(f'[new:] {json.dumps(new_card.get(field_name))}')
        choice = choose('use fields from [o]ld card, from [n]ew card with errata, or [e]dit manually?', ['old', 'new', 'edit'])
        if choice == 'old':
            return reprint_card, card_name, {
                field_name: old_card[field_name]
                for field_name in SIMPLE_FIELDS
                if field_name in old_card
            }
        elif choice == 'new':
            return reprint_card, card_name, {
                field_name: errata_card[field_name]
                for field_name in SIMPLE_FIELDS
                if field_name in errata_card
            }
        else:
            return reprint_card, card_name, json.loads('\n'.join(
                line
                for line in edit(card_diff(set_code, card_name, old_card, new_card, errata_card)).splitlines()
                if not line.strip().startswith('#')
            ))
    else:
        return reprint_card, card_name, {
            field_name: errata_card[field_name]
            for field_name in SIMPLE_FIELDS
            if field_name in errata_card
        }

def merge_set_jsons(set_json_path, ver_dir, *, old, new, errata, is_commander):
    set_json = copy.deepcopy(errata['data'])
    if 'boosterV3' not in set_json and not is_commander:
        if 'boosterV3' in old['data']:
            set_json['boosterV3'] = old['data']['boosterV3']
        else:
            set_json['boosterV3'] = input_default('boosterV3', ['common'] * 10 + ['uncommon'] * 3 + [['rare', 'mythic rare']], convert=json.loads)
    # build rename map
    name_map = build_name_map(ver_dir, old, errata)
    set_json['cards'] = []
    for errata_card in errata['data']['cards']:
        # if this is a reprint, find another printing
        reprint_card, reprint_set = max([
            (reprint_card, get_cached_set_file(iter_set_path))
            for iter_set_path in CUSTOM_SETS.iterdir()
            if iter_set_path.resolve() != set_json_path.resolve()
            for i, reprint_card in enumerate(get_cached_set_file(iter_set_path)['data']['cards'])
            if reprint_card['name'] == errata_card['name']
        ], key=lambda tup: (
            not tup[1]['data'].get('custom', False), # prefer official sets
            tup[1]['meta']['date'] # prefer newer MTG JSON compilation dates
        ), default=(None, None))
        if reprint_card is not None and reprint_set['data'].get('custom', False):
            print(f'[ ** ] reprint from {reprint_set["data"]["code"]}: {reprint_card["name"]}')
        for old_card in old['data'].get('cards', []):
            if old_card['name'] == name_map[errata_card['name']][0]:
                break
        else:
            old_card = None
        if name_map[errata_card['name']][1] is None:
            if old_card is not None and 'originalName' in old_card:
                original_name = old_card['originalName']
            else:
                original_name = errata_card['name']
        else:
            original_name = name_map[errata_card['name']][1]
        try:
            new_card = next(card for card in new['data']['cards'] if card['name'] == original_name)
        except StopIteration as e:
            print(f'[ !! ] no card named {original_name} (original name of {errata_card["name"]}) found in new set without errata')
            new_card = None
        reprint_card, card_name, card = merge_card_fields(reprint_card, old_card, new_card, errata_card, None if reprint_card is None else reprint_set['data']['code'], set_json['code'])
        if 'flavorText' in errata_card:
            card['flavorText'] = errata_card['flavorText']
        card['name'] = card_name
        if 'names' in errata_card:
            card['names'] = errata_card['names'] #TODO make sure any changes to any card's name from merge_card_fields are reflected here
        card['number'] = errata_card['number']
        if new_card is not None:
            card['originalName'] = new_card['name']
            if new_card.get('text', ''):
                card['originalText'] = new_card['text']
            card['originalType'] = new_card['type']
        if reprint_card is None:
            if old_card is None:
                card['rulings'] = edit_rulings(card_name, [])
            elif all((k in old_card) == (k in card) and old_card.get(k) == card.get(k) for k in set(SIMPLE_FIELDS) - PRINTING_SPECIFIC_FIELDS):
                card['rulings'] = old_card.get('rulings', [])
            else:
                card['rulings'] = edit_rulings(card_name, old_card.get('rulings', []))
        else:
            if old_card is None:
                card['rulings'] = reprint_card['rulings']
            else:
                card['rulings'] = sorted(reprint_card['rulings'] + [ruling for ruling in old_card['rulings'] if ruling not in reprint_card['rulings']], key=lambda ruling: ruling['date'])
        set_json['cards'].append(card)
    if 'releaseDate' not in set_json:
        if 'releaseDate' in old['data']:
            set_json['releaseDate'] = old['data']['releaseDate']
        else:
            set_json['releaseDate'] = input('[ ?? ] release date [YYYY-MM-DD]: ')
    if 'type' not in set_json:
        if 'type' in old['data']:
            set_json['type'] = old['data']['type']
        elif is_commander:
            set_json['type'] = 'commander'
        else:
            set_json['type'] = 'core' if yesno('is core set?') else 'expansion'
    return {
        'data': set_json,
        'meta': errata['meta']
    }

def parse_name_map(rename_path, *, inverted=False):
    if inverted:
        base_name_map, removed = parse_name_map(rename_path)
        name_map = {old_name: (None, None) for old_name in removed}
        added = set()
        for errata, (old, new) in base_name_map.items():
            if old is None:
                added.add(errata)
            else:
                name_map[old] = new, errata
        return name_map, added
    with rename_path.open(encoding='utf-8') as f:
        name_map_doc = f.read()
    name_map = {} # map new name with errata to (old name, new name without errata)
    removed = set()
    for i, line in enumerate(name_map_doc.splitlines()):
        if not line.strip():
            continue
        if line.strip().startswith('#'):
            continue
        match = re.fullmatch(' *FROM +([^ ]+) *', line)
        if match:
            continue #TODO check to make sure the previous version matches, if not, also check that version's name-changes.txt
        match = re.fullmatch(' *([^=]+?) *=> *([^=]+?) *=> *([^=]+?) *', line)
        if match:
            name_map[match.group(3)] = match.group(1), match.group(2)
            continue
        match = re.fullmatch(' *=> *([^=]+?) *', line)
        if match:
            name_map[match.group(1)] = None, None
            continue
        match = re.fullmatch(' *([^=]+?) *=> *', line)
        if match:
            removed.add(match.group(1))
            continue
        match = re.fullmatch(' *([^=]+?) *=> *([^=]+?) *', line)
        if match:
            name_map[match.group(2)] = match.group(1), match.group(2)
            continue
        raise ValueError(f'Failed to parse line {i + 1} in name map: {line!r}')
    return name_map, removed

def reprint_eq(field_name, old_field, new_field):
    def normalized_rules_text(text):
        if text is None:
            text = ''
        #text = text.replace('\u2212', '-') # replace Unicode minus used in Oracle text with ASCII hyphen-minus used in MSE
        text = re.sub(' ?\\(.*?\\)', '', text) # remove reminder text #TODO disable this normalization if the old card is from a custom set
        return text

    if old_field == new_field:
        return True
    if field_name == 'names' and not old_field and not new_field:
        return True # missing field same as empty list
    if field_name != 'text' and (old_field is None) != (new_field is None):
        return False
    #if isinstance(old_field, str) and new_field == old_field.replace('\u2212', '-'):
    #    return True
    if field_name in {'colors', 'colorIdentity', 'colorIndicator'} and set(old_field) == set(new_field):
        return True # only order of colors changed
    if field_name == 'text' and normalized_rules_text(old_field) == normalized_rules_text(new_field):
        return True # only reminder text changed
    return False

@subcommand
def ruling(*card_names):
    for ruling_text in iter(sys.stdin.readline, ''):
        num_printings = 0
        today = datetime.datetime.utcnow().date()
        for set_path in CUSTOM_SETS.iterdir():
            with set_path.open() as set_f:
                set_info = json.load(set_f)
            if 'data' in set_info:
                set_info_inner = set_info['data'] # MTG JSON 5
            else: # MTG JSON ≤4
                set_info_inner = set_info
            if not set_info_inner.get('custom', False):
                continue
            for card_info in set_info_inner['cards']:
                if card_info['name'] in card_names:
                    num_printings += 1
                    if 'rulings' not in card_info:
                        card_info['rulings'] = []
                    new_ruling = {
                        'date': f'{today:%Y-%m-%d}',
                        'text': ruling_text.strip()
                    }
                    if new_ruling not in card_info['rulings']:
                        card_info['rulings'].append(new_ruling)
            with set_path.open('w') as set_f:
                json.dump(set_info, set_f, indent=4, sort_keys=True)
                print(file=set_f)
        print(f'[ ** ] {num_printings} printing{"" if num_printings == 1 else "s"} updated')

def run_remote(command, check=True, **kwargs):
    return subprocess.run(['ssh', os.environ.get('LORE_SEEKER_HOSTNAME', 'laire'), *map(shlex.quote, command)], check=check, **kwargs)

def upload_card_image(set_code, card_id, image_path, is_token=False):
    art_path = image_path.parent / image_path.name.replace('.full.jpg', '.art.jpg')
    dir = BASE_PATH / 'repo' / 'frontend' / 'public' / ('tokens' if is_token else 'cards') / set_code.lower()
    art_dir = BASE_PATH / 'repo' / 'frontend' / 'public' / 'art' / set_code.lower()
    for i in range(5):
        try:
            run_remote(['mkdir', '-p', str(dir)])
            subprocess.run(['scp', str(image_path), f'{os.environ.get("LORE_SEEKER_HOSTNAME", "laire")}:{dir / (card_id + ".png")}'], check=True)
            subprocess.run(['scp', str(art_path), f'{os.environ.get("LORE_SEEKER_HOSTNAME", "laire")}:{art_dir / (card_id + ".png")}'], check=True)
        except subprocess.CalledProcessError:
            if i < 4:
                continue
            else:
                raise
        else:
            break

#TODO add options for --errata, --no-errata, --delete (delete all existing images for sets that will be uploaded before starting)
@subcommand('img')
def upload_images(set_code=None, version=None):
    """Upload custom card images to Lore Seeker."""
    global BASE_PATH

    if 'LORESEEKERDATA' not in os.environ:
        if yesno('Upload to dev?'):
            BASE_PATH = pathlib.PurePosixPath('/usr/local/share/fenhl/lore-seeker/dev')
        else:
            BASE_PATH = pathlib.PurePosixPath('/usr/local/share/fenhl/lore-seeker')
    # determine sets and versions
    if set_code is None:
        set_infos = {path.stem: lazyjson.File(path) for path in CUSTOM_SETS.iterdir() if lazyjson.File(path).get('custom', False)}
    elif set_code.endswith('..'):
        set_infos = {path.stem: lazyjson.File(path) for path in CUSTOM_SETS.iterdir() if lazyjson.File(path).get('custom', False) and path.stem >= set_code[:-2]}
    else:
        set_infos = {set_code_part: lazyjson.File(CUSTOM_SETS / f'{set_code_part}.json') for set_code_part in set_code.split(',')}
    if version is None:
        versions = {}
    else:
        versions = {set_code_part: version_part for set_code_part, version_part in itertools.zip_longest(set_code.split(','), version.split(','))}
    for set_code, set_info in sorted(set_infos.items()):
        if versions.get(set_code) is None:
            if 'setVersion' in set_info.get('meta', {}):
                versions[set_code] = set_info['meta']['setVersion'].value()
            elif 'version' in set_info:
                versions[set_code] = set_info['version'].value()
            else:
                version = input(f'[ ?? ] {set_info["name"]} version [leave blank to skip {set_code}]: ')
                if version != '':
                    versions[set_code] = version
    img_dirs_map = {set_code: img_dirs(set_infos[set_code]['data'].value(), version) for set_code, version in sorted(versions.items()) if version is not None}
    #TODO `mkdir trice-errata && mse.com --export magic-cockatrice-lore-seeker errata.mse-set trice-errata/{set_code}.xml`
    # upload artwork & full renders
    for set_code, version in sorted(versions.items()):
        if version is None:
            continue
        set_info = set_infos[set_code]['data'].value()
        set_name = set_info['name']
        set_dir = pathlib.Path.home() / 'games' / 'magic' / 'set' / set_code.lower()
        print(f'[ ** ] uploading images for {set_name} version {version}')
        card_count = collections.defaultdict(lambda: 0)
        # make sure target dirs exist and are empty
        run_remote(['rm', '-rf', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'art' / set_code.lower())], check=False)
        run_remote(['rm', '-rf', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'cards' / set_code.lower())], check=False)
        run_remote(['rm', '-rf', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'tokens' / set_code.lower())], check=False)
        run_remote(['mkdir', '-p', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'art' / set_code.lower())])
        run_remote(['mkdir', '-p', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'cards' / set_code.lower())])
        run_remote(['mkdir', '-p', str(BASE_PATH / 'repo' / 'frontend' / 'public' / 'tokens' / set_code.lower())])
        # determine source dir
        set_img_dirs = img_dirs_map[set_code]
        if len(set_img_dirs) == 1 and set_img_dirs[0].name.startswith('trice'):
            numbers = {}
            with (set_img_dirs[0] / f'{set_code}.xml').open() as noimg_xml:
                et = xml.etree.ElementTree.parse(noimg_xml)
                for card in et.findall('cards/card'):
                    pic_url = more_itertools.one(card.findall('set')).get('picURL')
                    match = re.fullmatch('https://lore-seeker\\.cards/(cards|tokens)/[0-9a-z]+/([0-9a-z]+)\\.png', pic_url)
                    if not match:
                        raise ValueError(f'Invalid picURL: {pic_url!r}')
                    cards_tokens, card_number = match.groups()
                    is_token = cards_tokens == 'tokens'
                    numbers[card.findtext('name')] = (is_token, card_number)
            with (set_img_dirs[0] / f'{set_code}-files' / f'{set_code}.xml').open() as img_xml:
                et = xml.etree.ElementTree.parse(img_xml)
                for card in et.findall('cards/card'):
                    pic_path = set_img_dirs[0] / f'{set_code}-files' / more_itertools.one(card.findall('set')).get('splitterPath')[1:]
                    is_token, card_number = numbers[card.findtext('name')]
                    upload_card_image(set_code, card_number, pic_path, is_token)
        else:
            set_img_dirs.append(set_dir / 'basics')
            # upload images
            for card_info in set_info['cards']:
                card_name = card_info['name']
                card_id = card_info['number']
                upload_card_image(set_code, card_id, img_filename(card_name, set_img_dirs, count=card_count[card_name], original_name=card_info.get('originalName')))
                card_count[card_name] += 1

@subcommand('update-precons')
def update_precons():
    set_infos = {path.stem: lazyjson.File(path).value() for path in CUSTOM_SETS.iterdir() if lazyjson.File(path).get('custom', False)}
    for set_code, set_info in sorted(set_infos.items()):
        if 'setVersion' in set_info.get('meta', {}):
            new_version = set_info['meta']['setVersion']
        elif 'version' in set_info:
            new_version = set_info['version']
        else:
            print(f'[ ** ] skipping {set_info["name"]} (no version info found)')
            continue
        set_dir = pathlib.Path.home() / 'games' / 'magic' / 'set' / set_code.lower()
        if not set_dir.exists():
            raise FileNotFoundError(f'No such set directory: {set_dir}')
        ver_dir = set_dir / f'v{new_version}'
        try:
            name_map_path = more_itertools.one(path for path in ver_dir.iterdir() if NAME_CHANGES_REGEX.fullmatch(path.name))
        except ValueError:
            print(f'[ !! ] no rename map in {ver_dir}')
            continue
        name_map = parse_name_map(name_map_path, inverted=True)[0]
        old_version = NAME_CHANGES_REGEX.fullmatch(name_map_path.name).group(1)
        for format, precons_path in PRECONS_PATHS.items():
            print(f'[....] updating {set_code} version from {old_version} to {new_version} in {format} decks', end='', flush=True)
            num_updated = 0
            with precons_path.open(encoding='utf-8') as f:
                precons = json.load(f)
            for deck in precons:
                for card_list_key in {'cards', 'sideboard', 'brawlers', 'commanders'}:
                    if card_list_key in deck:
                        for card_info in deck[card_list_key]:
                            new_name = name_map.get(card_info[4], (card_info[4], card_info[4]))[1]
                            if card_info[1] == set_code.lower() and card_info[2] == old_version and new_name is not None:
                                card_info[2] = new_version
                                card_info[4] = new_name
                                found_set_code, found_card_info = find_card(new_name, set_info)
                                if found_set_code != set_code:
                                    raise RuntimeError('Card is not in set')
                                else:
                                    card_info[3] = found_card_info['number']
                                num_updated += 1
            with precons_path.open('w', encoding='utf-8', newline='\n') as f:
                json.dump(precons, f, indent=4, sort_keys=True)
                print(file=f)
            print(f': {num_updated} cards updated\r[ ok ]')

def yesno(question):
    return choose(question, ['yes', 'no']) == 'yes'

if __name__ == '__main__':
    if sys.argv[1] in SUBCOMMANDS:
        result = SUBCOMMANDS[sys.argv[1]](*sys.argv[2:])
    else:
        sys.exit(f'[!!!!] No such subcommand. Available subcommands: {", ".join(sorted(SUBCOMMANDS))}')
    if isinstance(result, int):
        sys.exit(result)
    elif result is not None:
        print(result)
